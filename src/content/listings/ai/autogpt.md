---
name: "AutoGPT"
slug: "autogpt"
tagline: "Open-source platform to build, deploy, and run autonomous AI agents"
description: "AutoGPT is an open-source platform for creating and managing autonomous AI agents that can automate complex, multi-step workflows without constant human input. It supports self-hosting via Docker or a cloud-hosted beta, and provides a full suite of tools for building agent pipelines on top of LLMs. The project is one of the most widely recognized autonomous agent frameworks in the open-source AI ecosystem."
category: "ai"
subcategory: "agents"
tags: ["ai", "agents", "autonomous", "llm", "open-source", "developer-tools", "automation"]
website: "https://agpt.co"
github: "https://github.com/Significant-Gravitas/AutoGPT"
docs: "https://agpt.co/docs/platform/getting-started/getting-started"
pricing: "open-source"
status: "new"
dateAdded: 2026-02-19
featured: false
---

## Getting Started

1. **Install prerequisites** — Ensure you have Docker (20.10+), Docker Compose (2.0+), Git, Node.js (16+), and npm installed on your system.
2. **Run the setup script** — On macOS/Linux, run `curl -fsSL https://setup.agpt.co/install.sh -o install.sh && bash install.sh` to get up and running quickly. Windows users can use the equivalent PowerShell command.
3. **Configure your environment** — Set up your LLM API keys and any required environment variables as described in the official documentation.
4. **Launch and build** — Start the platform and begin creating agent workflows through the UI or programmatically via the provided SDKs.

## Key Features

- **Autonomous agents** — Build agents that execute long-running, multi-step tasks without requiring human input at each step.
- **Self-hosting support** — Run the entire platform locally using Docker Compose, free of charge, with full control over your data.
- **Cloud-hosted option** — A managed cloud beta is available for users who prefer not to handle infrastructure themselves.
- **Workflow automation** — Chain together actions, tools, and decisions into reusable agent pipelines for complex use cases.
- **LLM flexibility** — Designed to work with multiple large language models, not locked into a single provider.
- **Active open-source community** — Backed by a large Discord community and regularly maintained codebase with broad language documentation support.
