---
name: "Llama 4"
slug: "llama"
tagline: "Meta's open-weight foundation model family, leading open-source LLM"
description: "Llama 4 is Meta's latest open-weight large language model, offering state-of-the-art performance across reasoning, coding, and multilingual tasks. Available in multiple sizes from lightweight to frontier-class, it has become the backbone of the open-source AI ecosystem."
category: "ai"
subcategory: "llms"
tags: ["llm", "open-source", "meta", "foundation-model", "self-hosted"]
website: "https://llama.meta.com"
github: "https://github.com/meta-llama/llama"
docs: "https://llama.meta.com/docs"
pricing: "open-source"
status: "stable"
dateAdded: 2026-01-15
featured: false
---

## Getting Started

1. Visit [llama.meta.com](https://llama.meta.com) and request access to the Llama 4 model weights by agreeing to the community license.
2. Download the model weights via the official CLI or through Hugging Face Hub.
3. Run Llama locally using tools like Ollama, vLLM, or llama.cpp for optimized inference on consumer hardware.
4. Fine-tune the model on your own data using frameworks like Hugging Face Transformers or Axolotl.

## Key Features

- **Multiple model sizes** ranging from 8B to 405B parameters, enabling deployment from edge devices to data centers.
- **Open-weight license** allows commercial use, fine-tuning, and redistribution within Meta's community license terms.
- **State-of-the-art reasoning** competitive with closed-source models on math, coding, and general knowledge benchmarks.
- **Extensive ecosystem** with support across all major inference frameworks, cloud providers, and fine-tuning tools.
- **Multilingual support** across dozens of languages with strong performance on non-English benchmarks.
- **Optimized for efficiency** with grouped-query attention and other architectural improvements for faster inference.
